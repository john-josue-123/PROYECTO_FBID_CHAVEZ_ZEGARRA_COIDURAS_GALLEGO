####################################################################################
###################################################################################
###################################################################################
###################################################################################
###################################################################################
###################################################################################


Procedimiento para Iniciar KAFKA
================================

* sudo systemctl start kafka
	Check status
	*** sudo systemctl status kafka
* sudo systemctl enable zookeeper
* sudo systemctl enable kafka

Crear topico que piden en proyecto:
* ~/kafka/bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic flight_delay_classification_request

* Se envia mensaje usando echo:
echo "Asignatura FBID" | ~/kafka/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic flight_delay_classification_request > /dev/null

* Se enlista los mensajes enviados:
~/kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic flight_delay_classification_request --from-beginning

* Se enlista los topicos creados:
~/kafka/bin/kafka-topics.sh --zookeeper localhost:2181 --list


Procedimiento para iniciar MongoDB (Version 4.2):
===================================

Activar mongoDB:
* sudo systemctl start mongod
	To check: service mongod status
* sudo systemctl enable mongod

Ingresar a ~/Desktop/practica_big_data_2019 y ejecutar el comando:
* ./resources/import_distances.sh

Train and Save de the model with PySpark mllib
===============================================

* cd practica_big_data_2019
* export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-amd64
* export SPARK_HOME=/opt/spark

Ingresar a root 

* sudo su -
* ls -a
* nano .profile

Colocar esto en .profile:

export SPARK_HOME=/opt/spark
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-amd64
export PATH="$PATH:/root/.local/share/coursier/bin:$SPARK_HOME/bin:$SPARK_HOME/sbin"
export PYSPARK_PYTHON=/usr/bin/python3


su - jchavezz

Se ejecuta script ###### EJECUTAR ESTO AL INICIAR 
python3 resources/train_spark_mllib_model.py .

Desde resources visualizar:
ls models/   ##### TO WATCH THE FILES SAVED IN THE MODELS FOLDER


Run Flight Predictor
========================

Ingresar al directorio:
* /home/jchavezz/Desktop/practica_big_data_2019/flight_prediction/src/main/scala/es/upm/dit/ging/predictor/

Editar lo siguiente:
* val base_path= "/home/jchavezz/Desktop/practica_big_data_2019"

Ingresar al directorio flight_prediction
/home/jchavezz/Desktop/practica_big_data_2019/flight_prediction

En el directorio flight_prediction o ingresando a sbt
* sbt compile
* sbt run
Abrir otro terminal y entrar a la misma carpeta
* sbt package

"flight_prediction_2.12-0.1.jar" se genera dentro de /home/jchavezz/Desktop/practica_big_data_2019/flight_prediction/target/scala-2.12

Error al ejecutar "sbt run"

Lo que podría generar:

******* POSIBLE ERROR *******

~/spark/bin/spark-submit  /home/jchavezz/Desktop/practica_big_data_2019/flight_prediction/target/scala-2.12/flight_prediction_2.12-0.1.jar --packages org.mongodb.spark:mongo-spark-connector_2.12:3.0.1,org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2
   
   

Start the prediction request Wepb Application
================================================

Ingresar a root 

* sudo su -
* nano .profile
Colocar en .profile
* export PROJECT_HOME=/home/jchavezz/Desktop/practica_big_data_2019

Guardar

* su - jchavezz

Ingresar a directorio web:
* cd Desktop/practica_big_data_2019/resources/web

* python3 predict_flask.py  ##### PARA VER LOGs

Error:
  File "predict_flask.py", line 295, in <module>
    import joblib
Error ModuleNotFoundError: No module named 'joblib'
Solución: pip install joblib


Error:
Traceback (most recent call last):
  File "predict_flask.py", line 299, in <module>
    project_home = os.environ["PROJECT_HOME"]
  File "/usr/lib/python3.8/os.py", line 67d5, in __getitem__
    raise KeyError(key) from None
KeyError: 'PROJECT_HOME'
Solución: ejecutar en terminal: export PROJECT_HOME=/home/jchavezz/Desktop/practica_big_data_2019


Para revisar el correcto funcionamiento:

* http://localhost:5000/flights/delays/predict_kafka 

* Presionar => "Submit"



Check the predictions records inserted in MongoDB
===================================================

Ingresar a mongo

* $ mongo
* > use agile_data_science;
* > db.flight_delay_classification_response.find();




Train the model with Apache Airflow (optional)
================================================

++ ERROR: 
launchpadlib 1.10.13 requires testresources, which is not installed.
====> SOLUCIÓN: 
sudo apt install python3-testresources

### apt install pipenv
#### pipenv install

Ir a la carpeta airflow:

* cd resources/airflow
* pip install -r requirements.txt -c constraints.txt

Ejecutar y colocar en .profile según corresponda:

export PROJECT_HOME=/home/user/Desktop/practica_big_data_2019

export AIRFLOW_HOME=/home/user/Desktop/practica_big_data_2019/resources/airflow

Crear directorios:

** sudo mkdir $AIRFLOW_HOME/dags
** sudo mkdir $AIRFLOW_HOME/logs
** sudo mkdir $AIRFLOW_HOME/plugins

Ejecutar siempre que se empieza: 

** airflow users create --username admin  --firstname Jack   --lastname  Sparrow --role Admin --email example@mail.org

****** SOLICITA CONTRASEÑA *******
Admin user admin created
12345678


## INFORMACIÓN : Start airflow scheduler and webserver:
https://airflow.apache.org/docs/apache-airflow/1.10.14/start.html #

pip install apache-airflow

* airflow db init
* airflow webserver --port 8080    #### ABRIR UN TERMINAL APARTE
* airflow scheduler

Ingresar:

http://localhost:8080/home

Error: 
sqlite3.OperationalError: no such table: dag


###########################################
###########################################
###########################################
###########################################
###########################################
###########################################
##					 ##
##   EJECUTAR     ESTO    AL    INICIAR  ##
## 					 ##
###########################################
###########################################
###########################################
###########################################
###########################################

cat * | grep -r findspark 
para ver palabras en el sistema


export SPARK_HOME=/opt/spark
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-amd64
export PYSPARK_PYTHON=/usr/bin/python3
export PROJECT_HOME=/home/jchavezz/Desktop/practica_big_data_2019
export AIRFLOW_HOME=~/airflow

Ingresar desde kafka user:

~/kafka/bin/kafka-server-start.sh config/server.properties ##### DEJAR UN TERMINAL CON ESTO

~/kafka/bin/zookeeper-server-start.sh config/zookeeper.properties

Abrir en terminales diferentes si es posible:

 pip install -r requirements.txt

Ingresar desde el root la carpeta practica_big_data_2019:
=====> En caso de error por sc, ejecutar apt install sc

1.- python3 resources/train_spark_mllib_model.py . 

En el directorio flight_prediction o ingresando a sbt

./resources/import_distances.sh

2.- sbt compile
3.- sbt run ###############################     DEJAR UN TERMINAL CON ESTO
Abrir otro terminal y entrar a la misma carpeta
4.- sbt package #### Se generar el JAR


5.- ~/spark/bin/spark-submit  /home/jchavezz/Desktop/practica_big_data_2019/flight_prediction/target/scala-2.12/flight_prediction_2.12-0.1.jar --packages org.mongodb.spark:mongo-spark-connector_2.12:3.0.1,org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2


##### Desde root:

spark-submit  /home/jchavezz/Desktop/practica_big_data_2019/flight_prediction/target/scala-2.12/flight_prediction_2.12-0.1.jar --packages org.mongodb.spark:mongo-spark-connector_2.12:3.0.1,org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2



Ingresar a directorio web para ingresar datos:

6.- cd Desktop/practica_big_data_2019/resources/web

* export PROJECT_HOME=/home/user/Desktop/practica_big_data_2019

***** pip install joblib

7.- python3 predict_flask.py ###############################     DEJAR UN TERMINAL CON ESTO

Ingresar a otro terminal

8.-
